Тема
> Как проектировать события, схемы, потребителей, и защититься от дупликатов.


# Событийно-ориентированная архитектура (EDA)


Событийно-ориентированная архитектура (EDA) — это современный подход к построению систем, в котором малые независимые сервисы обмениваются *событиями*. Событие в контексте EDA — это значимое изменение состояния системы или сигнал о том, что что-то произошло (например, «заказ создан» или «файл загружен»). При такой архитектуре продюсеры (издатели) публикуют события в брокер сообщений или шину событий, а консюмеры (подписчики) асинхронно их получают и обрабатывают. Это снимает жесткую связь между сервисами: издатель не зависит от присутствия или скорости потребителей. Благодаря слабой связанности приложения легче масштабировать, обновлять и разворачивать независимо друг от друга. EDA часто сравнивают с рассылкой уведомлений: сервис просто *отправляет сообщение* о событии, а заинтересованные модули могут на него отреагировать, как хотят, не дожидаясь синхронного ответа.

**Плюсы событийно-ориентированной архитектуры (EDA)**

*   **Масштабируемость и эффективность:** Сервисы масштабируются независимо, обрабатывая пиковые нагрузки, не перегружая другие; сокращается необходимость в опросе (polling).
*   **Асинхронность и отзывчивость:** Компоненты реагируют в реальном времени; сервисы не ждут ответа друг от друга.
*   **Слабая связанность (Loose Coupling):** Производители и потребители событий независимы, что упрощает обновления и замену компонентов.
*   **Устойчивость и отказоустойчивость:** Сбои изолированы; сообщения помещаются в очередь, предотвращая потерю данных.
*   **Гибкость и расширяемость:** Легко добавлять новые сервисы (потребителей), реагирующие на существующие события.
*   **Лучше подходит для сложных систем:** Идеальна для микросервисов, IoT и облачно-нативных приложений, требующих высокой интерактивности.

**Минусы событийно-ориентированной архитектуры (EDA)**

*   **Возросшая сложность:** Больше компонентов (брокеры, события, обработчики) усложняют общее понимание системы.
*   **Сложности отладки и мониторинга:** Трассировка потоков событий между множеством сервисов затруднена (требуется распределённая трассировка).
*   **Порядок событий и согласованность:** Обеспечение корректной последовательности обработки событий может быть сложной задачей.
*   **Эксплуатационные накладные расходы:** Требует управления брокерами событий (такими как Kafka, RabbitMQ) и соответствующей инфраструктурой.
*   **Не для простых задач:** Добавляет избыточную сложность для линейных, простых или ресурсоёмких (CPU-bound) задач.
*   **Риск "over-engineering" (избыточной сложности):** Использование событий как RPC-вызовов, как отмечают пользователи Reddit, может привести к созданию сложных и связанных систем.

## Событие и схема: структура, версия и эволюция

**Структура события.** Событие обычно состоит из заголовка и тела. В заголовке могут быть метаданные: уникальный идентификатор события, его *тип* (например, `OrderCreated`), временная метка создания, версия схемы и др. Тело события (payload) содержит данные о произошедшем: это может быть полная информация о состоянии (например, название товара, количество и цена в заказе) или лишь ключевые поля/идентификаторы (например, «заказ № 8942 отправлен»). Такое разделение похоже на почтовое письмо: заголовок (конверт) говорит о том, что это за событие и когда, а содержимое (письмо) описывает детали.

**Схема события.** Схема (schema) определяет формат полезной нагрузки события: какие поля в нём есть и какого они типа. Обычно используют человекочитаемые форматы (JSON, Protobuf, Avro и т.д.) с явно описанной структурой. Наличие схемы помогает потребителям правильно интерпретировать данные и обнаруживать ошибки. Как отмечено в технической литературе, схема обеспечивает **согласованность** и надёжность передачи данных, задавая чёткий контракт между издателем и потребителем. Например, можно поддерживать реестр схем (Schema Registry) для хранения версий.

**Версионирование и эволюция.** Со временем может потребоваться изменить структуру события: добавить новое поле или изменить формат. Важно сохранить *обратную совместимость*: старые потребители должны по-прежнему корректно обрабатывать новые события. Для этого обычно применяют следующие подходы:
- **Добавление версии.** В заголовок или тело события включают поле `version` с номером версии схемы. По нему потребитель может определить, какую логику применять.
- **Добавление новых полей.** Рекомендуется вносить только **аддитивные** изменения (новые поля с значениями по умолчанию), а не удалять или переименовывать существующие. Тогда старые клиенты просто игнорируют незнакомые поля, а новые видят дополнительные данные.
- **Дублирование каналов/тем.** Можно разместить новые версии событий в отдельных потоках или темах (например, `OrderCreated-v2`), чтобы старый и новый потребители подписывались на нужный им поток. Минус — дублирование логики у издателя.
- **Реестр схем.** Использовать централизованный реестр, где каждый тип события имеет идентификатор схемы. Тогда издатель при отправке указывает ID схемы, а потребитель подгружает само описание. Это особенно удобно с Avro/Protobuf и Confluent Schema Registry, хотя не отменяет необходимости думать о совместимостью.

В целом, при эволюции схем важно тщательно документировать изменения и координировать их с командами-потребителями, чтобы избежать несовместимости данных.

## Продюсеры и консюмеры событий, гарантии доставки

В EDA существуют два основных вида компонентов: **издатели (продюсеры)**, которые генерируют и отправляют события в шину или очередь, и **потребители (консюмеры)**, которые подписываются на нужные события и обрабатывают их. Чаще всего между ними стоит брокер сообщений (например, Apache Kafka, RabbitMQ, Redis Streams), который действует как буфер и маршрутизатор. Издатель отправляет одно событие и сразу продолжает работу, не дожидаясь ответа потребителя. Это повышает отзывчивость и масштабируемость системы: издатель быстро публикует событие и не блокируется, а брокер обеспечивает надёжную доставку заинтересованным подписчикам. Такой подход позволяет локализовать сбои: один потребитель может упасть, а остальные продолжат получать события из брокера.

**Преимущества паттерна Pub/Sub:**
- Разделение ответственности. Разные подсистемы могут эволюционировать независимо и расширяться без знания друг о друге.
- Масштабируемость. Легко добавить новые сервисы-потребители или увеличить число инстансов уже подписанных, не изменяя издателя.
- Надёжность. Сообщения буферизуются в брокере: если один потребитель временно недоступен, он получит упущенные события при восстановлении. Это повышает отказоустойчивость системы.
- Асинхронность. Позволяет обрабатывать высокую нагрузку: издатель не ждёт подтверждения, что событие дошло до всех; инфраструктура обеспечивает доставку в фоновом режиме.

**Гарантии доставки.** Разные брокеры предлагают разные семантики доставки сообщений. Ключевые типы гарантий:

- **At-most-once (не более одного раза):** сообщение будет доставлено либо один раз, либо вовсе может быть проигнорировано. Гарантия «максимум один раз» может привести к потере сообщений, но они точно не дублируются.
- **At-least-once (хотя бы один раз):** сообщение гарантированно будет доставлено **минимум** один раз, но может быть отправлено **несколько раз**. Это самый распространённый режим (например, в Kafka по умолчанию). Его минус — возможное дублирование.
- **Exactly-once (строго один раз):** сообщение доставляется ровно один раз — идеальная ситуация. На практике обеспечивает отсутствие и потерь, и дублей. Однако такая семантика сложна в реализации: брокер и приложение должны использовать транзакции или другие механизмы согласованности.

Например, при **at-least-once** брокер может повторно отправить событие, если не получил подтверждение (ACK) от потребителя. При сбое сети или сбое сервиса продюсер/брокер нередко делают ретрай и таким образом могут появиться дубли. Поэтому, как пишет практическая документация, **из одного и того же источника одно сообщение может быть отправлено несколько раз, поэтому логику обработки стоит сделать идемпотентной**. Семантика exactly-once возможна (Kafka поддерживает транзакции), но часто достигается с помощью идемпотентности (см. ниже).

Таким образом, при проектировании сервисов в EDA важно понимать эти гарантии и стараться выбрать баланс между сложностью и надёжностью. Часто достаточно **гарантировать доставку хотя бы один раз** (чтобы ничего не потерять) и **избегать потерь, полагаясь на идемпотентную обработку**, вместо того чтобы добиваться сложного exactly-once на уровне брокера.

## Дубликаты событий: причины и защита

**Причины дубликатов.** Дублирование событий в распределённых системах происходит по разным причинам. Чаще всего оно связано с семантикой «at least once» и с сетевыми сбоями. Например, если потребитель (консюмер) упал после обработки, но до подтверждения брокеру, при рестарте тот может заново прислать то же событие. Аналогично, продюсер может повторно отправить событие, если не получил ответ или подтверждение доставки. Как отмечает документация Microsoft, при неидеальной сети «одно и то же сообщение может быть отправлено более одного раза».

**Как справиться с дублями.** Основной подход — сделать обработку *идемпотентной*. Это значит, что повторная обработка того же события не изменит результат ни больше, ни меньше, чем однократная. Практически для этого каждое событие должно иметь **уникальный идентификатор** (event ID или idempotency key), чтобы потребитель мог понять, что с таким событием уже работал. Алгоритм обработки с точки зрения потребителя примерно такой:

- При получении события сервис проверяет, обрабатывалось ли уже это событие (есть ли его ID в хранилище обработки).
- Если событие **уже было обработано**, сервис просто возвращает ранее сохранённый результат или пропускает повторную обработку.
- Если событие **новое**, сервис выполняет бизнес-логику и сохраняет метку о том, что этот ID обработан.

Этот подход позволяет обезопаситься от дублирующих вызовов. Например, без идемпотентности повторный запрос на списание денег с карты может списать их дважды, а с ключом идемпотентности сервер при повторе поймёт, что операция уже выполнена, и не станет списывать снова.

Кроме того, некоторые брокеры или мидлвары могут помогать бороться с дублями на уровне инфраструктуры (например, сохранять history message ID). Но даже если на уровне очереди не реализовано явное удаление дублей, **ответственность ложится на приложение**: именно оно должно обеспечить идемпотентность обработки.

## Идемпотентность: зачем нужна и как реализуется

**Понятие идемпотентности.** Идемпотентная операция — это такая, при повторении её эффект на системе не изменяется после первого выполнения. Проще говоря, повторный идентичный запрос (или событие) не должен ничего изменять сверх того, что уже сделало первое выполнение. В надежных распределённых системах это важно: клиент или система могут непреднамеренно отправить один и тот же запрос несколько раз (например, из-за таймаута), и чтобы избежать «двойного списания», операцию делают идемпотентной.

По умолчанию некоторые HTTP-методы уже идемпотентны (PUT, DELETE), но операции создания (POST) — нет. Тем не менее, и их можно сделать идемпотентными — добавляя уникальный ключ операции. **Idempotency Key** — это уникальный идентификатор запроса, который генерирует клиент и отправляет серверу вместе с запросом (обычно в заголовке). Ключ должен быть достаточно случайным (например, UUIDv4). Сервер, видя новый ключ, выполняет операцию и сохраняет ответ, связывая его с этим ключом. Если к нему поступает повторный запрос с тем же ключом, он просто отдаёт ранее сохранённый результат вместо повторного выполнения логики.

Например, если клиент дважды отправит запрос на списание денег, сервер при наличии идемпотентного ключа при втором запросе вернёт тот же ответ, **не списав денег повторно**. Таким образом система защищена от дублирующих запросов (и, аналогично, от дублированных сообщений из очереди) без изменения бизнес-логики операций.

**Реализация.** Обычно идемпотентность выносится на инфраструктурный слой (например, middleware). При получении события или запроса проверяется его Idempotency-Key (или event ID). Если ключ ранее уже встречался, возвращается сохранённый ответ. Если нет — обрабатывается как новый. Для этого надо **где-то хранить информацию** об уже обработанных ключах и результатах.

*Где хранить токены идемпотентности (Idempotency Keys).* Есть два популярных подхода:

- **Реляционная база данных (PostgreSQL).** Надёжнее всего сохранить ключи в общей базе. Для этого создают таблицу, например `idempotency_keys`, с полем `key` (PRIMARY KEY) и данными результата (статус и тело ответа). При получении события сервис пытается вставить запись с новым ключом. Уникальность ключа гарантируется ограничением БД. Чтобы избежать гонок при параллельной обработке (две нити вставят один и тот же ключ почти одновременно), обычно делают транзакцию с блокировкой. Тогда один запрос вставит запись со статусом «processing», а второй, проснувшись, увидит, что ключ уже есть, и либо дождётся результата первого, либо вернёт ответ, не выполняя логику второй раз. Недостаток подхода в задержках: каждая операция идемпотентности требует обращения к БД (INSERT и UPDATE).

- **Redis или быстрый кэш.** Часто используют Redis как распределённое хранилище токенов. В Redis можно хранить пары `ключ -> результат`. Redis доступен всем инстансам сервиса и очень быстр. Минус в том, что данные «периодические» (volatile): при сбросе кэша или перезапуске информация исчезнет. Но для идемпотентности достаточно хранить ключи лишь недолго (например, сутки), ведь маловероятно, что клиент по ошибке повторит старую операцию через недели. При работе с Redis важно использовать атомарные команды, чтобы избежать гонок. Например, командой `SET key "processing" EX 60 NX` можно одним запросом создать ключ только если его ещё нет. Первое выполнение установит ключ (и «захватит» его), а повторные попытки сразу увидят, что ключ занят, и поймут, что операция уже в процессе.

Таким образом, **идемпотентный токен** (ключ) нужен, чтобы отличать новые вызовы от повторных. Его обычно генерирует клиент или продюсер события и передаётся вместе с событием. Сами токены хранят либо в БД (надёжно, но медленнее) либо в Redis/кэше (быстро, но с ограниченным временем жизни). Выбор зависит от требований: Redis подойдёт для высоких нагрузок и кратковременных операций, PostgreSQL — когда нужно полное сохранение истории и согласованность.

**Пример:** представьте интернет-магазин. Клиент нажал «оплатить заказ» и отправил запрос на списание денег. Из-за проблемы сети клиент не получил ответ и через секунду нажал ещё раз. Без идемпотентности платёжный сервис спишет деньги дважды. С идемпотентным ключом (один и тот же для повторного запроса) сервис при втором сообщении увидит, что операция с этим ключом уже выполнена, и **не выполнит её заново**, вернув клиенту тот же ответ.

## Заключение

Событийно-ориентированная архитектура даёт гибкость и надёжность системам за счёт асинхронной передачи данных и слабой связанности сервисов. Однако она требует продуманного проектирования событий и их схем, внимания к версиям и совместимости, а также учёта свойств доставки сообщений. В частности, режимы доставки (at-least-once, at-most-once, exactly-once) влияют на появление дубликатов, поэтому критически важно делать обработку **идемпотентной**. Идемпотентные операции с использованием уникальных токенов запросов позволяют защитить систему от двойной обработки и сохранить корректность данных. При грамотном соблюдении этих принципов EDA-системы получают высокую масштабируемость, отказоустойчивость и могут обрабатывать события надёжно и эффективно.

**Источники:** концепции и определения событийно-ориентированной архитектуры и семантики доставки сообщений взяты из авторитетных публикаций и документации.
